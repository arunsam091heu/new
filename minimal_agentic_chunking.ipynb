{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ðŸ§ª Minimal Agentic Chunking Notebook (Module-by-Module)\n\nThis lightweight notebook lets you test each step **individually**:\n1) Extract blocks â†’ 2) Build outline â†’ 3) Plan chunks â†’ 4) Synthesize chunks â†’ 5) Embeddings â†’ 6) Visualize bbox.\n\n> Works **with** Azure OpenAI or **without** (falls back to simple heuristics).\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Install dependencies"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "!pip install -q pymupdf openai>=1.50.0 pydantic matplotlib numpy"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Configure environment"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import os\nos.environ.setdefault(\"AZURE_OPENAI_API_KEY\", \"\")\nos.environ.setdefault(\"AZURE_OPENAI_ENDPOINT\", \"https://<your-resource>.openai.azure.com\")\nos.environ.setdefault(\"AZURE_OPENAI_API_VERSION\", \"2024-08-01-preview\")\nos.environ.setdefault(\"AZURE_OPENAI_CHAT_DEPLOYMENT\", \"gpt-4o-mini\")\nos.environ.setdefault(\"AZURE_OPENAI_EMB_DEPLOYMENT\", \"text-embedding-3-large\")\nprint(\"Endpoint:\", os.environ.get(\"AZURE_OPENAI_ENDPOINT\"))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Imports & basic types"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import re, json, hashlib, textwrap\nfrom dataclasses import dataclass, asdict\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport fitz  # PyMuPDF\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntry:\n    from openai import AzureOpenAI\n    _openai_sdk = True\nexcept Exception as e:\n    print(\"OpenAI SDK import error:\", e)\n    _openai_sdk = False\n\nfrom pydantic import BaseModel, Field\n\nAZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")\nAZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\")\nAZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-08-01-preview\")\nCHAT_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\", \"gpt-4o-mini\")\nEMB_DEPLOYMENT  = os.getenv(\"AZURE_OPENAI_EMB_DEPLOYMENT\", \"text-embedding-3-large\")\n\nclient = None\nif _openai_sdk and AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT:\n    try:\n        client = AzureOpenAI(api_key=AZURE_OPENAI_API_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=AZURE_OPENAI_API_VERSION)\n        print(\"Azure OpenAI client ready.\")\n    except Exception as e:\n        print(\"Could not init Azure client:\", e)\n\n@dataclass\nclass Block:\n    page: int\n    text: str\n    bbox_points: Tuple[float, float, float, float]\n    page_size: Tuple[float, float]\n    kind: str\n    max_font: float\n    is_ocr: bool = False\n\n@dataclass\nclass Chunk:\n    id: str\n    section_path: List[str]\n    role: str\n    text: str\n    summary: str\n    keywords: List[str]\n    page_start: int\n    page_end: int\n    bboxes_norm: List[List[float]]\n    page_size: Dict[str, float]\n    source_pdf: str\n    source_anchor: str\n    metadata: Dict[str, Any]\n    embedding: Optional[List[float]] = None\n\nHEADING_RX = re.compile(r\"^\\s*(\\d+(\\.\\d+)*[\\).\\s-]+)?[A-Z].{0,80}$\")\n\ndef classify_kind(txt: str, max_font: float) -> str:\n    txt = (txt or \"\").strip()\n    if not txt: return \"para\"\n    if len(txt) < 120 and (HEADING_RX.match(txt) or max_font >= 14.5): return \"heading\"\n    if txt.startswith((\"-\", \"*\", \"â€¢\")): return \"list\"\n    return \"para\"\n\ndef norm_bbox(bbox, w, h):\n    x0,y0,x1,y1 = bbox\n    return [x0/w, y0/h, x1/w, y1/h]\n\ndef hash_id(*parts: str) -> str:\n    return hashlib.sha256(\"|\".join(p[:512] for p in parts).encode()).hexdigest()[:16]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Module A â€” Extract blocks"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "PDF_PATH = \"./your.pdf\"  # ðŸ‘ˆ change to your file path\n\ndef extract_blocks(pdf_path: str) -> List[Block]:\n    doc = fitz.open(pdf_path)\n    out: List[Block] = []\n    for pno in range(len(doc)):\n        page = doc[pno]\n        w, h = page.rect.width, page.rect.height\n        raw = page.get_text(\"rawdict\")\n        if not raw or not raw.get(\"blocks\"):\n            continue\n        for b in raw[\"blocks\"]:\n            if \"lines\" not in b: \n                continue\n            max_font = 0.0\n            parts = []\n            for line in b[\"lines\"]:\n                for span in line.get(\"spans\", []):\n                    parts.append(span.get(\"text\",\"\"))\n                    try:\n                        max_font = max(max_font, float(span.get(\"size\", 0)))\n                    except Exception:\n                        pass\n            txt = \"\\n\".join(parts).strip()\n            if not txt: \n                continue\n            out.append(Block(page=pno+1, text=txt, bbox_points=tuple(b[\"bbox\"]), page_size=(w,h), kind=classify_kind(txt, max_font), max_font=max_font))\n    return out\n\nblocks = extract_blocks(PDF_PATH)\nprint(f\"Extracted blocks: {len(blocks)}\")\nif blocks:\n    print(\"Sample -> page:\", blocks[0].page, \"| kind:\", blocks[0].kind)\n    print(blocks[0].text[:300], \"...\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Module B â€” Build outline"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def build_outline(blocks: List[Block]) -> List[Dict[str, Any]]:\n    path: List[str] = []\n    outline: List[Dict[str, Any]] = []\n    for b in blocks:\n        if b.kind == \"heading\":\n            path = [*path, b.text][-6:]\n        outline.append({\"path\": path[:], \"block\": b})\n    return outline\n\noutline = build_outline(blocks)\nprint(\"Outline entries:\", len(outline))\nif outline:\n    print(\"First path:\", \" > \".join(outline[0][\"path\"]))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Module C â€” Plan chunks (LLM or fallback)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from pydantic import BaseModel, Field\n\nclass PlanItem(BaseModel):\n    start_index: int = Field(..., ge=0)\n    end_index: int   = Field(..., ge=0)\n    role: str        = Field(...)\n    title: str       = Field(...)\n\ndef plan_chunks(outline: List[Dict[str, Any]], max_preview: int = 900) -> List[PlanItem]:\n    if client is None:\n        chunks, start = [], 0\n        acc_len = 0\n        title = outline[start][\"block\"].text[:60] if outline else \"Chunk\"\n        for i, row in enumerate(outline):\n            acc_len += len(row[\"block\"].text)\n            if row[\"block\"].kind == \"heading\" and i > start and acc_len > 1500:\n                chunks.append(PlanItem(start_index=start, end_index=i-1, role=\"other\", title=title))\n                start, acc_len = i, len(row[\"block\"].text)\n                title = row[\"block\"].text[:60]\n        if outline:\n            chunks.append(PlanItem(start_index=start, end_index=len(outline)-1, role=\"other\", title=title))\n        return chunks\n    preview = []\n    for i, row in enumerate(outline[:max_preview]):\n        b: Block = row[\"block\"]\n        preview.append({\"i\": i, \"page\": b.page, \"kind\": b.kind, \"text\": b.text[:350]})\n    system = \"You are a precise editor. Emit coherent chunk boundaries for the sequence of blocks.\"\n    user = {\"rules\": [\"Merge short paragraphs\", \"Prefer ~1.5â€“2.5k chars per chunk\",\n                      \"Return JSON list of {start_index,end_index,role,title}\"], \"preview\": preview}\n    res = client.chat.completions.create(\n        model=CHAT_DEPLOYMENT, temperature=0,\n        response_format={\"type\": \"json_object\"},\n        messages=[{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":json.dumps(user)}]\n    )\n    data = json.loads(res.choices[0].message.content)\n    items = data.get(\"chunks\") or data.get(\"results\") or []\n    return [PlanItem(**x) for x in items]\n\nplan = plan_chunks(outline)\nprint(\"Planned chunks:\", len(plan))\nif plan:\n    print(\"First plan:\", plan[0].model_dump())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Module D â€” Synthesize chunks (summary & keywords)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def summarize_and_keywords(text: str):\n    if client is None:\n        summary = (text.strip().split(\". \")[0] if text else \"\")[:400]\n        kws = list({w.strip(',.;:()[]{}').lower() for w in text.split() if 3 <= len(w) <= 15})[:6]\n        return summary, kws\n    prompt = f\"\"\"Summarize in 1â€“2 sentences. Then a line 'Keywords:' with 3â€“8 terse keywords.\\n\\n{textwrap.shorten(text, width=4800, placeholder=' ...')}\"\"\"\n    r = client.chat.completions.create(model=CHAT_DEPLOYMENT, temperature=0,\n        messages=[{\"role\":\"system\",\"content\":\"Be concise.\"},{\"role\":\"user\",\"content\":prompt}]\n    ).choices[0].message.content or \"\"\n    lines = [ln.strip() for ln in r.splitlines() if ln.strip()]\n    summary = lines[0][:500] if lines else \"\"\n    kws = []\n    for ln in lines[::-1]:\n        if ln.lower().startswith(\"keywords:\"):\n            kws = [k.strip().strip(',.;') for k in ln.split(':',1)[1].split(',') if k.strip()]\n            break\n    return summary, kws\n\ndef synthesize_chunks(pdf_path: str, outline: List[Dict[str, Any]], plan: List[PlanItem]) -> List[Chunk]:\n    chunks: List[Chunk] = []\n    for item in plan:\n        seg = outline[item.start_index : item.end_index + 1]\n        text_parts, pages, bboxes = [], [], []\n        path = []\n        ref_w = ref_h = None\n        for row in seg:\n            b: Block = row[\"block\"]\n            if b.kind == \"heading\":\n                path.append(b.text)\n            text_parts.append(b.text)\n            pages.append(b.page)\n            pw, ph = b.page_size\n            if ref_w is None:\n                ref_w, ref_h = pw, ph\n            bboxes.append(norm_bbox(b.bbox_points, pw, ph))\n        content = \"\\n\".join(text_parts).strip()\n        summary, keywords = summarize_and_keywords(content)\n        cid = hash_id(pdf_path, str(min(pages) if pages else 1), item.title, content[:512])\n        chunks.append(Chunk(\n            id=cid, section_path=path[-4:] or [\"Document\"], role=item.role, text=content,\n            summary=summary, keywords=keywords,\n            page_start=min(pages) if pages else 1, page_end=max(pages) if pages else 1,\n            bboxes_norm=bboxes, page_size={\"width\": ref_w or 0, \"height\": ref_h or 0},\n            source_pdf=pdf_path, source_anchor=f\"page={min(pages) if pages else 1}\",\n            metadata={\"title\": item.title, \"pages\": pages}\n        ))\n    return chunks\n\nchunks = synthesize_chunks(PDF_PATH, outline, plan)\nprint(\"Synthesized chunks:\", len(chunks))\nif chunks:\n    print(\"First chunk summary:\", chunks[0].summary)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8) Module E â€” Embeddings (Azure or fallback)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def embed_text(text: str) -> List[float]:\n    if client is None:\n        h = hashlib.sha256(text.encode()).digest()\n        arr = np.frombuffer(h, dtype=np.uint8).astype(np.float32)\n        vec = (arr - arr.mean()) / (arr.std() + 1e-6)\n        return vec.tolist()[:128]\n    e = client.embeddings.create(model=EMB_DEPLOYMENT, input=text)\n    return e.data[0].embedding\n\nfor c in chunks[:5]:\n    comp = f\"{c.text[:1500]}\\n{' '.join(c.keywords)}\\n{' / '.join(c.section_path)}\"\n    c.embedding = embed_text(comp)\n\nprint('First chunk embedding length:', len(chunks[0].embedding) if chunks else None)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9) Module F â€” Visualize a chunk's bounding boxes on the page"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def show_chunk_overlay(pdf_path: str, chunk: Chunk, dpi: int = 150):\n    doc = fitz.open(pdf_path)\n    page_index = max(0, chunk.page_start - 1)\n    page = doc[page_index]\n    mat = fitz.Matrix(dpi/72, dpi/72)\n    pix = page.get_pixmap(matrix=mat, alpha=False)\n    img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n    fig, ax = plt.subplots(figsize=(10, 10 * pix.h / pix.w))\n    ax.imshow(img); ax.axis('off')\n    for bb in chunk.bboxes_norm:\n        x0 = bb[0] * pix.w; y0 = bb[1] * pix.h\n        x1 = bb[2] * pix.w; y1 = bb[3] * pix.h\n        rect = plt.Rectangle((x0, y0), (x1-x0), (y1-y0), fill=False, linewidth=2)\n        ax.add_patch(rect)\n    plt.show()\n\nif chunks:\n    show_chunk_overlay(PDF_PATH, chunks[0], dpi=180)\nelse:\n    print(\"No chunks to visualize.\")"
    }
  ]
}